{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3.6",
   "display_name": "Python 3.6.13  ('python3.6': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /root/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import ast\n",
    "import spacy\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_2015 = pd.read_csv('data/korea_herald_2015_30_ver_preprocessing.csv')\n",
    "article_2016 = pd.read_csv('data/korea_herald_2016_30_ver_preprocessing.csv')\n",
    "article_2017 = pd.read_csv('data/korea_herald_2017_30_ver_preprocessing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(rawtext):\n",
    "    document = rawtext\n",
    "    document = re.sub(r'said', '', document)\n",
    "\n",
    "    # Remove date\n",
    "    dates = ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'week', 'next', 'month', 'year']\n",
    "    for date in dates:\n",
    "        document = re.sub(r'{}'.format(date), '', document)\n",
    "    \n",
    "    # Remove publisher\n",
    "    document = re.sub(r'korea herald', ' ', document)\n",
    "    document = re.sub(r'history textbooks', ' ', document)\n",
    "    document = re.sub(r'history textbook', ' ', document)\n",
    "\n",
    "    # Remove president name\n",
    "    # document = re.sub(r'president', ' ', document)\n",
    "    document = re.sub(r'south korea', ' ', document)\n",
    "    document = re.sub(r'north korea', ' ', document)\n",
    "    document = re.sub(r'seoul', ' ', document)\n",
    "\n",
    "    document = re.sub(r'president park', ' ', document)\n",
    "    document = re.sub(r'korean geun', ' ', document)\n",
    "    document = re.sub(r'geun', ' ', document)\n",
    "    document = re.sub(r'geun hye', ' ', document)\n",
    "    document = re.sub(r'president hye', ' ', document)\n",
    "\n",
    "    document = re.sub(r'president moon', ' ', document)\n",
    "    document = re.sub(r'moon jae', ' ', document)\n",
    "    document = re.sub(r'korean jae', ' ', document)\n",
    "    document = re.sub(r'korea', ' ', document)\n",
    "    document = re.sub(r'korean', ' ', document)\n",
    "\n",
    "    # document = re.sub(r'us donald', ' ', document)\n",
    "    document = document.replace('us donald', ' ')\n",
    "    document = document.replace('donald', ' ')\n",
    "    document = document.replace('trump', ' ')\n",
    "    document = document.replace('us', ' ')\n",
    "\n",
    "    document = re.sub(r'kim jong', ' ', document)\n",
    "\n",
    "    document = re.sub(r'\\s+', ' ', document)\n",
    "    return document\n",
    "    \n",
    "def remove_duplicates(candidates):\n",
    "    result = []\n",
    "    for cand in candidates:\n",
    "        is_duplicate = False\n",
    "        for cand2 in candidates:\n",
    "            if cand == cand2:\n",
    "                continue\n",
    "            if cand in cand2:\n",
    "                is_duplicate = True\n",
    "                break\n",
    "        if not is_duplicate:\n",
    "            result.append(cand)\n",
    "    return result\n",
    "    \n",
    "def capital(string):\n",
    "    string_list = string.split()\n",
    "    string_list = [s.capitalize() for s in string_list]\n",
    "    return ' '.join(string_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==========[0]:249==========\n",
      "Topic: ['china launched', 'barack obama', 'president barack', 'nuclear envoy', 'stage winter drills', 'president barack obama', 'postpone trip', 'trip postpone trip', 'winter drills', 'trip postpone']\n",
      "Docs number: 249\n",
      "==========[1, 13, 16, 19]:1049==========\n",
      "Topic: ['nuclear weapons', 'nuclear test', 'military drills', 'ballistic missile', 'nuclear tests', 'new nuclear', 'nuclear envoy', 'nuclear warheads', 'pend nuclear', 'nuclear talks']\n",
      "Docs number: 1049\n",
      "==========[2]:179==========\n",
      "Topic: ['financial regulator', 'youth unemployment', 'fourth largest', '17 billion', 'fourth largest economy', 'climate change', 'top 30', '20 million', 'largest economy', 'antitr watchdog']\n",
      "Docs number: 179\n",
      "==========[3, 5, 11]:588==========\n",
      "Topic: ['sex slavery', 'sex slaves', 'japan wartime', 'sexual slavery', 'wartime sex', 'wartime sexual', 'wartime sex slavery', 'wartime sexual slavery', 'japanese prime', 'sexual enslavement']\n",
      "Docs number: 588\n",
      "==========[4]:268==========\n",
      "Topic: ['former president', 'president kim', 'foreign minister', 'presidential spokesman', 'presidential office', 'late president', 'winter olympics', 'presidential election', 'visit china', 'opposition leader']\n",
      "Docs number: 268\n",
      "==========[6]:352==========\n",
      "Topic: ['foreign minister', 'beijing beijing', 'former president', 'nuclear envoy', 'military parade', 'meeting meeting', 'top diplomat', 'chinese tourists', 'visit china', 'disc pyongyang']\n",
      "Docs number: 352\n",
      "==========[7, 8, 9, 23]:934==========\n",
      "Topic: ['arrest warrant', 'bribery scandal', 'prosecutors raided', 'prime minister', 'opposition party', 'new politics', 'presidential election', 'main opposition', 'jail term', 'ruling party']\n",
      "Docs number: 934\n",
      "==========[8, 9]:457==========\n",
      "Topic: ['opposition party', 'new politics', 'prime minister', 'main opposition', 'rival parties', 'ruling party', 'floor leader', 'presidential election', 'bribery scandal', 'parties agreed']\n",
      "Docs number: 457\n",
      "==========[10, 12]:353==========\n",
      "Topic: ['fishing boat', 'capsized fishing', 'found dead', 'capsized fishing boat', 'ferry sinking', 'deadly ferry', 'helicopter crashed', 'killing four', 'sunken ferry', 'guard helicopter']\n",
      "Docs number: 353\n",
      "==========[14, 28, 29]:505==========\n",
      "Topic: ['female activists', 'anti pyongyang', 'survey showed', 'data showed', '30 female activists', '30 female', 'protest rally', 'ho ewife', 'elderly women', 'government data']\n",
      "Docs number: 505\n",
      "==========[15]:186==========\n",
      "Topic: ['opposition lawmakers', 'opposition party', 'ruling party', 'opposition lawmaker', 'main opposition', 'party lawmaker', 'rival parties', 'party leader', 'prime minister', 'acc ed']\n",
      "Docs number: 186\n",
      "==========[17]:171==========\n",
      "Topic: ['respiratory syndrome', 'new cases', 'bird flu', 'samsung medical', 'avian influenza', 'death toll', 'new patients', 'three new', 'health authorities', 'reported three']\n",
      "Docs number: 171\n",
      "==========[18, 24, 26, 27]:1150==========\n",
      "Topic: ['military parade', 'barack obama', 'president barack', 'family reunions', 'president barack obama', 'former president', 'parade china', 'foreign minister', 'president president', 'nuclear talks']\n",
      "Docs number: 1150\n",
      "==========[20]:181==========\n",
      "Topic: ['severe drought', 'fourth largest', 'fourth largest economy', 'third largest', 'largest economy', 'foreign tourists', 'illegal fishing', 'chinese tourists', 'wage hike', 'new tunnel']\n",
      "Docs number: 181\n",
      "==========[21]:362==========\n",
      "Topic: ['2015 world', 'olympic swimming', 'climate change', 'daejeon 2015', 'world science', 'war veterans', 'daejeon 2015 world', '2015 world science', 'food 2015', 'cab drivers']\n",
      "Docs number: 362\n",
      "==========[22]:172==========\n",
      "Topic: ['suicide rate', 'soldier defected', 'defected soldier', 'young ns', 'soldier defected soldier', 'sex slaves', 'fifth largest', 'new ambassador', 'first nuclear', 'worst drought']\n",
      "Docs number: 172\n",
      "==========[25]:284==========\n",
      "Topic: ['air force', 'pyongyang media', 'foreign ministry', 'state media', 'media reported', 'ns convicted', 'unification ministry', 'barack obama', 'first lady', 'finance ministry']\n",
      "Docs number: 284\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# 2015 koreaherald article topic extraction #\n",
    "#############################################\n",
    "updated_cluster_2015 = [[0], [1, 13, 16, 19], [2], [3, 5, 11], [4], [6], [7, 8, 9, 23], [8, 9], [10, 12], [14, 28, 29], [15], [17], [18, 24, 26, 27], [20], [21], [22], [25]]\n",
    "top_2015 = dict()\n",
    "\n",
    "for i in updated_cluster_2015:\n",
    "    keyword_set = article_2015[article_2015['cluster'].isin(i)].keyword\n",
    "    doc_num = len(keyword_set)\n",
    "    # keyword_set = [preprocessing(keyword) for keyword_list in keyword_set for keyword in keyword_list]\n",
    "    # keyword_text = ''.join(keyword_set)\n",
    "    keyword_set = [preprocessing(keyword.replace(' ,', ' ')) for keyword in keyword_set]\n",
    "\n",
    "    vectorizer = CountVectorizer(max_features=1500, ngram_range=(2, 5), min_df=1, max_df=doc_num/3, stop_words=stopwords.words('english'))\n",
    "    X_count = vectorizer.fit_transform(keyword_set).toarray()\n",
    "    X_tfidf = TfidfTransformer().fit_transform(X_count).toarray()\n",
    "\n",
    "    result = pd.DataFrame(X_count, columns= vectorizer.get_feature_names())\n",
    "    # print('max frequency', max(result.sum(axis=0)))\n",
    "    result = list(result.sum(axis=0).sort_values(ascending=False).keys()[:100])\n",
    "\n",
    "    print('=========={}:{}=========='.format(i, doc_num))\n",
    "    # print(remove_duplicates(result)[:15])\n",
    "    print('Topic:', result[:10])\n",
    "    print('Docs number:', doc_num)\n",
    "    top_2015[capital(result[0])] = doc_num\n",
    "print('============================')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==========[0, 1, 3, 6, 11, 12, 13, 23, 28]:2500==========\n",
      "Topic: ['nuclear test', 'fourth nuclear', 'fourth nuclear test', 'latest nuclear', 'fifth nuclear', 'fifth nuclear test', 'ballistic missile', 'latest nuclear test', 'rocket launch', 'recent nuclear']\n",
      "Docs number: 2500\n",
      "==========[2, 10, 17, 18, 22, 27]:1269==========\n",
      "Topic: ['corruption scandal', 'scandal involving', 'prosecutors raided', 'opposition parties', 'involving president', 'scandal surrounding', 'peddling scandal', 'former presidential', 'opposition party', 'scandal involving president']\n",
      "Docs number: 1269\n",
      "==========[4, 7, 20, 29]:734==========\n",
      "Topic: ['presidential race', 'presidential election', 'presidential candidate', 'republican presidential', 'barack obama', 'president barack', 'president barack obama', 'race presidential', 'presidential race presidential', 'republican presidential candidate']\n",
      "Docs number: 734\n",
      "==========[5, 8]:567==========\n",
      "Topic: ['sex slavery', 'sexual slavery', 'wartime sexual', 'defectors defectors', 'wartime sexual slavery', 'japan wartime', 'sex slaves', 'slavery victims', 'three nobel', 'late president']\n",
      "Docs number: 567\n",
      "==========[9]:184==========\n",
      "Topic: ['jail term', 'found dead', 'sexually harassing', 'murder pect', 'drowned student', 'ex girlfriend', 'murder charges', 'gangnam murder', 'ab ive', 'student local']\n",
      "Docs number: 184\n",
      "==========[14]:173==========\n",
      "Topic: ['000 ns', 'percent ns', 'ho eholds', 'women women', 'half ns', 'college graduates', '10 ns', 'ns aged', 'young ns', 'teen runaways']\n",
      "Docs number: 173\n",
      "==========[15]:196==========\n",
      "Topic: ['magnitude earthquake', 'nuclear test', 'zika vir', 'quake magnitude', 'following magnitude', 'heavy rain', 'magnitude aftershock', 'quake hit', 'following magnitude earthquake', 'quake stricken']\n",
      "Docs number: 196\n",
      "==========[16]:204==========\n",
      "Topic: ['found dead', 'gang rape', 'attempts suicide', 'acc ed', 'fishing boat', 'taxi driver', 'car accident', 'ex girlfriend', 'police officer', 'band woman']\n",
      "Docs number: 204\n",
      "==========[19]:164==========\n",
      "Topic: ['chinese fishing', 'illegal fishing', 'bird flu', 'fishing boats', 'boats illegally', 'illegal chinese fishing', 'illegal chinese', 'illegally fishing', 'chinese boats', 'chinese fishing boats']\n",
      "Docs number: 164\n",
      "==========[21]:186==========\n",
      "Topic: ['survey showed', 'pregnant women', 'data showed', 'fell percent', 'university students', 'married women', 'suicide risk', 'pregnant women died', '000 new', 'unemployment benefits']\n",
      "Docs number: 186\n",
      "==========[24]:198==========\n",
      "Topic: ['record high', 'hit record', 'government data', 'data showed', 'million foreigners', 'ho eholds', 'government data showed', 'half ns', '500 ns', 'million last']\n",
      "Docs number: 198\n",
      "==========[25]:206==========\n",
      "Topic: ['college student', 'police arrested', 'airport police', 'found dead', 'murder pect', 'massive spam', 'chinese fishermen', 'hackers sent', 'incheon airport', 'arrested arrested']\n",
      "Docs number: 206\n",
      "==========[26]:245==========\n",
      "Topic: ['chinese tourists', 'expo 2016', 'master zookeeper', 'city tour', 'host luncheon', 'opening ceremony', 'beijing basketball', 'world largest', 'defense expo', 'innovative entrepreneurship']\n",
      "Docs number: 245\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# 2016 koreaherald article topic extraction #\n",
    "#############################################\n",
    "updated_cluster_2016 = [[0, 1, 3, 6, 11, 12, 13, 23, 28], [2, 10, 17, 18, 22, 27], [4, 7, 20, 29], [5, 8], [9], [14], [15], [16], [19], [21], [24], [25], [26]]\n",
    "top_2016 = dict()\n",
    "for i in updated_cluster_2016:\n",
    "    keyword_set = article_2016[article_2016['cluster'].isin(i)].keyword\n",
    "    doc_num = len(keyword_set)\n",
    "    # keyword_set = [preprocessing(keyword) for keyword_list in keyword_set for keyword in keyword_list]\n",
    "    # keyword_text = ''.join(keyword_set)\n",
    "    keyword_set = [preprocessing(keyword.replace(' ,', ' ')) for keyword in keyword_set]\n",
    "\n",
    "    vectorizer = CountVectorizer(max_features=1500, ngram_range=(2, 5), min_df=1, max_df=doc_num/3, stop_words=stopwords.words('english'))\n",
    "    X_count = vectorizer.fit_transform(keyword_set).toarray()\n",
    "    X_tfidf = TfidfTransformer().fit_transform(X_count).toarray()\n",
    "\n",
    "    result = pd.DataFrame(X_count, columns= vectorizer.get_feature_names())\n",
    "    # print('max frequency', max(result.sum(axis=0)))\n",
    "    result = list(result.sum(axis=0).sort_values(ascending=False).keys()[:100])\n",
    "\n",
    "    print('=========={}:{}=========='.format(i, doc_num))\n",
    "    # print(remove_duplicates(result)[:15])\n",
    "    print('Topic:', result[:10])\n",
    "    print('Docs number:', doc_num)\n",
    "    top_2016[capital(result[0])] = doc_num\n",
    "print('============================')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==========[0]:252==========\n",
      "Topic: ['conservative presidents', 'acting president', 'old daughter', 'two conservative', 'slavery died', 'two conservative presidents', 'impeached former', 'stealing cash', 'new astronaut', 'minister vows', 'female pilots', 'presidential race', 'vacation looming', 'ho eplants', 'female assassins', 'energy minister', 'grieving mother', 'army soldier', '11 hamsters', 'presidential front', 'revenge porn', 'bashes obama', 'nephew tired', 'emergency surgery', 'epidemic cows', 'commit suicide', '000 contract', 'new education', 'eplants looking', 'sia trip']\n",
      "Docs number: 252\n",
      "==========[1, 5, 8, 11, 12, 25, 28]:2126==========\n",
      "Topic: ['nuclear test', 'ballistic missile', 'missile launch', 'latest missile', 'missile test', 'latest nuclear', 'nuclear weapons', 'intercontinental ballistic', 'latest nuclear test', 'military drills', 'test latest', 'sixth nuclear', 'sixth nuclear test', 'latest missile test', 'ballistic missiles', 'intercontinental ballistic missile', 'latest missile launch', 'nuclear missile', 'missile tests', 'nuclear nuclear', 'test latest nuclear', 'nuclear warhead', 'latest ballistic', 'nuclear test latest nuclear', 'missile latest', 'nuclear test latest', 'new missile', 'latest nuclear test latest', 'latest nuclear test latest nuclear', 'recent missile']\n",
      "Docs number: 2126\n",
      "==========[2, 19]:703==========\n",
      "Topic: ['winter olympics', 'pyeongchang winter', 'pyeongchang olympics', 'pyeongchang winter olympics', '2018 pyeongchang', '2018 pyeongchang winter', 'winter games', 'olympics pyeongchang', 'pyeongchang 2018', '2018 pyeongchang winter olympics', 'presidential election', 'winter olympics pyeongchang', 'president president', 'winter olympic', 'olympics winter', 'olympics winter olympics', 'acting president', 'barack obama', 'winter olympics winter', '2018 winter', 'olympics pyeongchang winter', 'upcoming winter', 'president barack obama', 'president barack', 'mayor park', 'top diplomat', 'winter olympics winter olympics', 'olympic games', 'former president', 'olympics pyeongchang winter olympics']\n",
      "Docs number: 703\n",
      "==========[3]:232==========\n",
      "Topic: ['scientists develop', 'found dead', 'scientists scientists', 'presidential contest', 'scientists developed', 'soldier defected', 'woman found', 'woman found dead', 'presidential contest presidential', 'taxi driver', 'soldier defected soldier', 'defected soldier', 'contest presidential', '000 ns', 'relocation japan', 'scientists discovered', 'corruption scandal', 'raped stepdaughter', 'police arrested', 'ethnic chinese', 'hackers target', 'ab ed girlfriend', 'ly childbirths', 'boat collided', 'presidential contest presidential contest', 'university classmate', 'fishing boat collided', 'ab ed', 'scientists scientists developed', 'contest presidential contest']\n",
      "Docs number: 232\n",
      "==========[4, 15]:645==========\n",
      "Topic: ['corruption scandal', 'arrest warrant', 'former president', 'impeachment trial', 'scandal prosecutors', 'prosecutors prosecutors', 'scandal involving', 'presidential aide', 'samsung heir', 'prosecutors raided', 'bribery charges', 'special prosecutors', 'bribery allegations', 'park impeachment', 'election meddling', 'impeached president', 'corruption allegations', 'ted president', 'prosecutors questioned', 'trial impeachment', 'corruption charges', 'president impeachment', 'prosecutors seek', 'spy agency', 'presidential election', 'jail term', 'involving president', 'trial impeachment trial', 'meddling scandal', 'former presidential']\n",
      "Docs number: 645\n",
      "==========[6]:287==========\n",
      "Topic: ['sewol ferry', 'ferry sinking', 'magnitude quake', 'second strongest', 'fishing boat', 'fire broke', 'strongest quake', 'heat wave', 'ferry sank', 'sewol ferry sinking', 'salvaged sewol ferry', 'nuclear test', 'fish market', 'salvaged sewol', 'nine missing', 'bird flu', '2014 ferry', 'caught fire', 'chinese fishing', 'last earthquake', 'second strongest quake', 'ferry sewol', 'international airport', 'sunken sewol ferry', 'strongest earthquake', 'sunken sewol', 'nuclear reactors', 'salvage operators', 'missing passengers', 'second strongest earthquake']\n",
      "Docs number: 287\n",
      "==========[7, 9, 14, 17, 18, 20, 22, 23, 24]:2651==========\n",
      "Topic: ['presidential election', 'presidential candidate', 'president president', 'acting president', 'upcoming presidential', 'presidential race', 'upcoming presidential election', 'may presidential', 'may presidential election', 'presidential candidates', 'election presidential', 'front runner', 'presidential hopefuls', 'presidential front', 'democratic party', 'impeachment trial', 'former president', 'presidential election presidential', 'new president', 'presidential front runner', 'presidential bid', 'election presidential election', 'opposition parties', 'presidential election presidential election', 'corruption scandal', 'presidential hopeful', 'foreign minister', 'presidential contender', 'ruling party', 'presidential presidential']\n",
      "Docs number: 2651\n",
      "==========[10]:201==========\n",
      "Topic: ['found dead', 'fishing boat', 'police arrested', 'female students', 'attempted murder', 'sexual assault', 'high school', 'murdering wife', 'sexual harassment', 'drunk driving', 'arrested stealing', 'sexually assaulting', 'sexually harassed', 'police officer', 'police police', 'sexually assaulted', 'bar employees', 'sexually harassing', 'woman arrested', 'ex girlfriend', 'murder pect', 'child ab', 'police arrest', '24 smartphones', 'harassed female', 'assaulting bar', 'female army', 'assaulted tralian', 'capsized fishing', 'teacher arrested']\n",
      "Docs number: 201\n",
      "==========[13]:206==========\n",
      "Topic: ['bird flu', 'avian influenza', 'social media', 'insecticide contaminated', 'contaminated egg', 'world worst', 'h5n6 bird flu', 'h5n6 bird', 'fishing vessel', 'traffic deaths', 'migrant workers', '29 000', 'insecticide contaminated egg', 'tainted egg', 'egg products', '29 000 accidents', 'helicopters lack', '000 accidents', '000 ducks', '10 greenho', 'sanitary pads', 'egg crisis', 'banning yoga', 'anthrax vaccines', 'severe drought', 'killer whale', 'nuclear reactors', 'first cat', 'contaminated eggs', 'megawatt reactor']\n",
      "Docs number: 206\n",
      "==========[16]:204==========\n",
      "Topic: ['soldier defection', 'defection soldier', 'serial killers', 'ns killed', 'notorio serial', 'defectors defectors', 'hackers stole', 'japan wartime', 'notorio serial killers', 'recently rescued', 'fishermen rescued', 'propaganda leaflets', 'soldier defection soldier', 'wartime sexual', 'soldier defected soldier', '200 ns killed', 'soldier defected', 'defected soldier', 'presidential election', '10 women', '200 ns', 'sexual slavery', 'japan wartime sexual', 'fishermen recently', 'rescued sailors', 'girl statue', 'soldier defecting', 'opposition lawmakers', 'teenagers outstripping', 'marines fired']\n",
      "Docs number: 204\n",
      "==========[21]:237==========\n",
      "Topic: ['air pollution', 'suicide rate', 'fourth largest', 'largest economy', 'dog meat', 'fourth largest economy', 'government data', 'chinese visitors', 'asia fourth largest', 'asia fourth', 'million last', 'tallest skyscraper', '4th cholera', 'since 2013', 'minimum wage', 'lowest suicide rate', 'trillion billion', 'lowest suicide', 'bird flu', 'data showed', 'government data showed', 'third corrupt', 'asia fourth largest economy', 'diplomatic hiat', 'decline since', 'record low', 'raised 53', 'winter olympics', '2016 2016', 'death rate']\n",
      "Docs number: 237\n",
      "==========[26]:383==========\n",
      "Topic: ['top diplomat', 'state media', 'white ho', 'foreign ministry', 'nuclear test', 'missile launch', 'foreign minister', 'chinese president', 'unification minister', 'news report', 'broadcaster reported', 'nuclear weapons', 'defense ministry', 'media reported', 'top military', 'government official', 'unification ministry', 'ministry official', 'presidential office', 'ministry dismissed', 'former president', 'vice foreign', 'report germany', 'cyber attack', '20 summit', 'ho official', 'sanctions north', 'denounces japan', 'human rights', 'summit president']\n",
      "Docs number: 383\n",
      "==========[27]:327==========\n",
      "Topic: ['half brother', 'nam murder', 'sexual slavery', 'wartime sexual', 'japan wartime', 'japan wartime sexual', 'jong nam', 'wartime sexual slavery', 'enslavement women', 'sexual enslavement', 'college student', 'canadian pastor', 'japan wartime sexual slavery', 'murder murder', 'soldier killed', 'brother killed', 'jong nam murder', 'sex slavery', 'nam killing', 'murdering murdering', 'kim murder', 'sex slaves', 'recent murder', 'murder malaysia', 'murder pect', 'late leader', 'killing killing', 'spy chief', 'murdering woman', 'teen murder']\n",
      "Docs number: 327\n",
      "==========[29]:204==========\n",
      "Topic: ['cancer patients', 'survey showed', 'data showed', '10 ns', 'ho eholds', 'ns support', '10 teenage', 'ns ns', '353 foreigners', 'poll showed', 'study showed', 'malaria patients', 'majority ns', '2023 danish', 'government data', '2017 report', '20 percent', 'declines residents', 'defectors defectors', 'teenage prostitutions', 'defectors drops', 'less chinese', 'married late', 'study children', 'million people', 'ns negative', '70 percent', 'nearly half', 'asthma patients', 'nationals ly']\n",
      "Docs number: 204\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# 2017 koreaherald article topic extraction #\n",
    "#############################################\n",
    "updated_cluster_2017 = [[0], [1, 5, 8, 11, 12, 25, 28], [2, 19], [3], [4, 15], [6], [7, 9, 14, 17, 18, 20, 22, 23, 24], [10], [13], [16], [21], [26], [27], [29]]\n",
    "top_2017 = dict()\n",
    "\n",
    "for i in updated_cluster_2017:\n",
    "    keyword_set = article_2017[article_2017['cluster'].isin(i)].keyword\n",
    "    doc_num = len(keyword_set)\n",
    "    # keyword_set = [preprocessing(keyword) for keyword_list in keyword_set for keyword in keyword_list]\n",
    "    # keyword_text = ''.join(keyword_set)\n",
    "    keyword_set = [preprocessing(keyword.replace(' ,', ' ')) for keyword in keyword_set]\n",
    "\n",
    "    vectorizer = CountVectorizer(max_features=1500, ngram_range=(2, 5), min_df=1, max_df=doc_num/3, stop_words=stopwords.words('english'))\n",
    "    X_count = vectorizer.fit_transform(keyword_set).toarray()\n",
    "    X_tfidf = TfidfTransformer().fit_transform(X_count).toarray()\n",
    "\n",
    "    result = pd.DataFrame(X_count, columns= vectorizer.get_feature_names())\n",
    "    # print('max frequency', max(result.sum(axis=0)))\n",
    "    result = list(result.sum(axis=0).sort_values(ascending=False).keys()[:100])\n",
    "\n",
    "    print('=========={}:{}=========='.format(i, doc_num))\n",
    "    # print(remove_duplicates(result)[:15])\n",
    "    print('Topic:', result[:30])\n",
    "    print('Docs number:', doc_num)\n",
    "    top_2017[capital(result[0])] = doc_num\n",
    "print('============================')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2015] Top10 Topic\n('Military Parade', 1150) ('Nuclear Weapons', 1049) ('Sex Slavery', 588) ('Female Activists', 505) ('Arrest Warrant', 477) ('Opposition Party', 457) ('2015 World', 362) ('Fishing Boat', 353) ('Foreign Minister', 352) ('Air Force', 284) \n\n[2016] Top10 Topic\n('Nuclear Test', 2500) ('Corruption Scandal', 1269) ('Presidential Race', 734) ('Sex Slavery', 567) ('Chinese Tourists', 245) ('College Student', 206) ('Found Dead', 204) ('Record High', 198) ('Magnitude Earthquake', 196) ('Survey Showed', 186) \n\n[2017] Top10 Topic\n('Presidential Election', 2651) ('Nuclear Test', 2126) ('Winter Olympics', 703) ('Corruption Scandal', 645) ('Top Diplomat', 383) ('Half Brother', 327) ('Sewol Ferry', 287) ('Conservative Presidents', 252) ('Air Pollution', 237) ('Scientists Develop', 232) \n"
     ]
    }
   ],
   "source": [
    "top10_2015 = sorted(top_2015.items(), reverse=True, key=lambda x: x[1])[:10]\n",
    "top10_2016 = sorted(top_2016.items(), reverse=True, key=lambda x: x[1])[:10]\n",
    "top10_2017 = sorted(top_2017.items(), reverse=True, key=lambda x: x[1])[:10]\n",
    "print('[2015] Top10 Topic')\n",
    "for topic in top10_2015:\n",
    "    print(topic, end=' ')\n",
    "print()\n",
    "print()\n",
    "print('[2016] Top10 Topic')\n",
    "for topic in top10_2016:\n",
    "    print(topic, end=' ')\n",
    "print()\n",
    "print()\n",
    "print('[2017] Top10 Topic')\n",
    "for topic in top10_2017:\n",
    "    print(topic, end=' ')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}